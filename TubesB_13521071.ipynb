{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.Sequential import Sequential\n",
    "from lib.Layer import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = pd.Series(iris.target)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan splitting data train dan validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[iris.feature_names], df['target'], test_size=0.3, random_state=42, stratify=df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4) (105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model ANN\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(6, activation='sigmoid', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='linear', input_shape=(6,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "105/105 [==============================] - loss: 3.3727 - time: 0.0060 s\n",
      "Epoch 2/1000\n",
      "105/105 [==============================] - loss: 3.0352 - time: 0.0034 s\n",
      "Epoch 3/1000\n",
      "105/105 [==============================] - loss: 2.4048 - time: 0.0040 s\n",
      "Epoch 4/1000\n",
      "105/105 [==============================] - loss: 1.8375 - time: 0.0040 s\n",
      "Epoch 5/1000\n",
      "105/105 [==============================] - loss: 1.7142 - time: 0.0040 s\n",
      "Epoch 6/1000\n",
      "105/105 [==============================] - loss: 1.6875 - time: 0.0036 s\n",
      "Epoch 7/1000\n",
      "105/105 [==============================] - loss: 1.6644 - time: 0.0040 s\n",
      "Epoch 8/1000\n",
      "105/105 [==============================] - loss: 1.6433 - time: 0.0060 s\n",
      "Epoch 9/1000\n",
      "105/105 [==============================] - loss: 1.6217 - time: 0.0000 s\n",
      "Epoch 10/1000\n",
      "105/105 [==============================] - loss: 1.5990 - time: 0.0087 s\n",
      "Epoch 11/1000\n",
      "105/105 [==============================] - loss: 1.5747 - time: 0.0040 s\n",
      "Epoch 12/1000\n",
      "105/105 [==============================] - loss: 1.5484 - time: 0.0030 s\n",
      "Epoch 13/1000\n",
      "105/105 [==============================] - loss: 1.5196 - time: 0.0030 s\n",
      "Epoch 14/1000\n",
      "105/105 [==============================] - loss: 1.4876 - time: 0.0030 s\n",
      "Epoch 15/1000\n",
      "105/105 [==============================] - loss: 1.4519 - time: 0.0025 s\n",
      "Epoch 16/1000\n",
      "105/105 [==============================] - loss: 1.4120 - time: 0.0040 s\n",
      "Epoch 17/1000\n",
      "105/105 [==============================] - loss: 1.3674 - time: 0.0000 s\n",
      "Epoch 18/1000\n",
      "105/105 [==============================] - loss: 1.3176 - time: 0.0000 s\n",
      "Epoch 19/1000\n",
      "105/105 [==============================] - loss: 1.2625 - time: 0.0000 s\n",
      "Epoch 20/1000\n",
      "105/105 [==============================] - loss: 1.2026 - time: 0.0139 s\n",
      "Epoch 21/1000\n",
      "105/105 [==============================] - loss: 1.1387 - time: 0.0027 s\n",
      "Epoch 22/1000\n",
      "105/105 [==============================] - loss: 1.0708 - time: 0.0000 s\n",
      "Epoch 23/1000\n",
      "105/105 [==============================] - loss: 1.0030 - time: 0.0000 s\n",
      "Epoch 24/1000\n",
      "105/105 [==============================] - loss: 0.9473 - time: 0.0154 s\n",
      "Epoch 25/1000\n",
      "105/105 [==============================] - loss: 0.9037 - time: 0.0016 s\n",
      "Epoch 26/1000\n",
      "105/105 [==============================] - loss: 0.8661 - time: 0.0000 s\n",
      "Epoch 27/1000\n",
      "105/105 [==============================] - loss: 0.8286 - time: 0.0000 s\n",
      "Epoch 28/1000\n",
      "105/105 [==============================] - loss: 0.7879 - time: 0.0125 s\n",
      "Epoch 29/1000\n",
      "105/105 [==============================] - loss: 0.7435 - time: 0.0044 s\n",
      "Epoch 30/1000\n",
      "105/105 [==============================] - loss: 0.6969 - time: 0.0000 s\n",
      "Epoch 31/1000\n",
      "105/105 [==============================] - loss: 0.6519 - time: 0.0000 s\n",
      "Epoch 32/1000\n",
      "105/105 [==============================] - loss: 0.6122 - time: 0.0000 s\n",
      "Epoch 33/1000\n",
      "105/105 [==============================] - loss: 0.5811 - time: 0.0143 s\n",
      "Epoch 34/1000\n",
      "105/105 [==============================] - loss: 0.5591 - time: 0.0032 s\n",
      "Epoch 35/1000\n",
      "105/105 [==============================] - loss: 0.5420 - time: 0.0025 s\n",
      "Epoch 36/1000\n",
      "105/105 [==============================] - loss: 0.5263 - time: 0.0031 s\n",
      "Epoch 37/1000\n",
      "105/105 [==============================] - loss: 0.5114 - time: 0.0032 s\n",
      "Epoch 38/1000\n",
      "105/105 [==============================] - loss: 0.4978 - time: 0.0030 s\n",
      "Epoch 39/1000\n",
      "105/105 [==============================] - loss: 0.4856 - time: 0.0024 s\n",
      "Epoch 40/1000\n",
      "105/105 [==============================] - loss: 0.4751 - time: 0.0000 s\n",
      "Epoch 41/1000\n",
      "105/105 [==============================] - loss: 0.4664 - time: 0.0000 s\n",
      "Epoch 42/1000\n",
      "105/105 [==============================] - loss: 0.4593 - time: 0.0134 s\n",
      "Epoch 43/1000\n",
      "105/105 [==============================] - loss: 0.4534 - time: 0.0000 s\n",
      "Epoch 44/1000\n",
      "105/105 [==============================] - loss: 0.4485 - time: 0.0045 s\n",
      "Epoch 45/1000\n",
      "105/105 [==============================] - loss: 0.4442 - time: 0.0000 s\n",
      "Epoch 46/1000\n",
      "105/105 [==============================] - loss: 0.4403 - time: 0.0000 s\n",
      "Epoch 47/1000\n",
      "105/105 [==============================] - loss: 0.4366 - time: 0.0150 s\n",
      "Epoch 48/1000\n",
      "105/105 [==============================] - loss: 0.4330 - time: 0.0080 s\n",
      "Epoch 49/1000\n",
      "105/105 [==============================] - loss: 0.4297 - time: 0.0060 s\n",
      "Epoch 50/1000\n",
      "105/105 [==============================] - loss: 0.4264 - time: 0.0184 s\n",
      "Epoch 51/1000\n",
      "105/105 [==============================] - loss: 0.4234 - time: 0.0022 s\n",
      "Epoch 52/1000\n",
      "105/105 [==============================] - loss: 0.4204 - time: 0.0000 s\n",
      "Epoch 53/1000\n",
      "105/105 [==============================] - loss: 0.4176 - time: 0.0000 s\n",
      "Epoch 54/1000\n",
      "105/105 [==============================] - loss: 0.4150 - time: 0.0134 s\n",
      "Epoch 55/1000\n",
      "105/105 [==============================] - loss: 0.4125 - time: 0.0030 s\n",
      "Epoch 56/1000\n",
      "105/105 [==============================] - loss: 0.4101 - time: 0.0030 s\n",
      "Epoch 57/1000\n",
      "105/105 [==============================] - loss: 0.4078 - time: 0.0030 s\n",
      "Epoch 58/1000\n",
      "105/105 [==============================] - loss: 0.4056 - time: 0.0020 s\n",
      "Epoch 59/1000\n",
      "105/105 [==============================] - loss: 0.4035 - time: 0.0030 s\n",
      "Epoch 60/1000\n",
      "105/105 [==============================] - loss: 0.4014 - time: 0.0042 s\n",
      "Epoch 61/1000\n",
      "105/105 [==============================] - loss: 0.3994 - time: 0.0061 s\n",
      "Epoch 62/1000\n",
      "105/105 [==============================] - loss: 0.3975 - time: 0.0026 s\n",
      "Epoch 63/1000\n",
      "105/105 [==============================] - loss: 0.3956 - time: 0.0091 s\n",
      "Epoch 64/1000\n",
      "105/105 [==============================] - loss: 0.3938 - time: 0.0035 s\n",
      "Epoch 65/1000\n",
      "105/105 [==============================] - loss: 0.3920 - time: 0.0030 s\n",
      "Epoch 66/1000\n",
      "105/105 [==============================] - loss: 0.3902 - time: 0.0024 s\n",
      "Epoch 67/1000\n",
      "105/105 [==============================] - loss: 0.3885 - time: 0.0037 s\n",
      "Epoch 68/1000\n",
      "105/105 [==============================] - loss: 0.3867 - time: 0.0040 s\n",
      "Epoch 69/1000\n",
      "105/105 [==============================] - loss: 0.3851 - time: 0.0000 s\n",
      "Epoch 70/1000\n",
      "105/105 [==============================] - loss: 0.3834 - time: 0.0000 s\n",
      "Epoch 71/1000\n",
      "105/105 [==============================] - loss: 0.3817 - time: 0.0000 s\n",
      "Epoch 72/1000\n",
      "105/105 [==============================] - loss: 0.3801 - time: 0.0149 s\n",
      "Epoch 73/1000\n",
      "105/105 [==============================] - loss: 0.3785 - time: 0.0040 s\n",
      "Epoch 74/1000\n",
      "105/105 [==============================] - loss: 0.3769 - time: 0.0030 s\n",
      "Epoch 75/1000\n",
      "105/105 [==============================] - loss: 0.3753 - time: 0.0030 s\n",
      "Epoch 76/1000\n",
      "105/105 [==============================] - loss: 0.3737 - time: 0.0030 s\n",
      "Epoch 77/1000\n",
      "105/105 [==============================] - loss: 0.3721 - time: 0.0040 s\n",
      "Epoch 78/1000\n",
      "105/105 [==============================] - loss: 0.3706 - time: 0.0030 s\n",
      "Epoch 79/1000\n",
      "105/105 [==============================] - loss: 0.3691 - time: 0.0040 s\n",
      "Epoch 80/1000\n",
      "105/105 [==============================] - loss: 0.3675 - time: 0.0030 s\n",
      "Epoch 81/1000\n",
      "105/105 [==============================] - loss: 0.3660 - time: 0.0035 s\n",
      "Epoch 82/1000\n",
      "105/105 [==============================] - loss: 0.3645 - time: 0.0028 s\n",
      "Epoch 83/1000\n",
      "105/105 [==============================] - loss: 0.3630 - time: 0.0030 s\n",
      "Epoch 84/1000\n",
      "105/105 [==============================] - loss: 0.3615 - time: 0.0030 s\n",
      "Epoch 85/1000\n",
      "105/105 [==============================] - loss: 0.3601 - time: 0.0035 s\n",
      "Epoch 86/1000\n",
      "105/105 [==============================] - loss: 0.3586 - time: 0.0025 s\n",
      "Epoch 87/1000\n",
      "105/105 [==============================] - loss: 0.3572 - time: 0.0028 s\n",
      "Epoch 88/1000\n",
      "105/105 [==============================] - loss: 0.3557 - time: 0.0000 s\n",
      "Epoch 89/1000\n",
      "105/105 [==============================] - loss: 0.3543 - time: 0.0000 s\n",
      "Epoch 90/1000\n",
      "105/105 [==============================] - loss: 0.3529 - time: 0.0000 s\n",
      "Epoch 91/1000\n",
      "105/105 [==============================] - loss: 0.3515 - time: 0.0000 s\n",
      "Epoch 92/1000\n",
      "105/105 [==============================] - loss: 0.3501 - time: 0.0186 s\n",
      "Epoch 93/1000\n",
      "105/105 [==============================] - loss: 0.3488 - time: 0.0030 s\n",
      "Epoch 94/1000\n",
      "105/105 [==============================] - loss: 0.3474 - time: 0.0000 s\n",
      "Epoch 95/1000\n",
      "105/105 [==============================] - loss: 0.3461 - time: 0.0000 s\n",
      "Epoch 96/1000\n",
      "105/105 [==============================] - loss: 0.3447 - time: 0.0106 s\n",
      "Epoch 97/1000\n",
      "105/105 [==============================] - loss: 0.3434 - time: 0.0020 s\n",
      "Epoch 98/1000\n",
      "105/105 [==============================] - loss: 0.3421 - time: 0.0000 s\n",
      "Epoch 99/1000\n",
      "105/105 [==============================] - loss: 0.3409 - time: 0.0000 s\n",
      "Epoch 100/1000\n",
      "105/105 [==============================] - loss: 0.3396 - time: 0.0000 s\n",
      "Epoch 101/1000\n",
      "105/105 [==============================] - loss: 0.3384 - time: 0.0000 s\n",
      "Epoch 102/1000\n",
      "105/105 [==============================] - loss: 0.3372 - time: 0.0194 s\n",
      "Epoch 103/1000\n",
      "105/105 [==============================] - loss: 0.3360 - time: 0.0000 s\n",
      "Epoch 104/1000\n",
      "105/105 [==============================] - loss: 0.3348 - time: 0.0126 s\n",
      "Epoch 105/1000\n",
      "105/105 [==============================] - loss: 0.3336 - time: 0.0006 s\n",
      "Epoch 106/1000\n",
      "105/105 [==============================] - loss: 0.3325 - time: 0.0000 s\n",
      "Epoch 107/1000\n",
      "105/105 [==============================] - loss: 0.3313 - time: 0.0000 s\n",
      "Epoch 108/1000\n",
      "105/105 [==============================] - loss: 0.3302 - time: 0.0000 s\n",
      "Epoch 109/1000\n",
      "105/105 [==============================] - loss: 0.3291 - time: 0.0163 s\n",
      "Epoch 110/1000\n",
      "105/105 [==============================] - loss: 0.3280 - time: 0.0030 s\n",
      "Epoch 111/1000\n",
      "105/105 [==============================] - loss: 0.3270 - time: 0.0030 s\n",
      "Epoch 112/1000\n",
      "105/105 [==============================] - loss: 0.3260 - time: 0.0030 s\n",
      "Epoch 113/1000\n",
      "105/105 [==============================] - loss: 0.3250 - time: 0.0030 s\n",
      "Epoch 114/1000\n",
      "105/105 [==============================] - loss: 0.3240 - time: 0.0020 s\n",
      "Epoch 115/1000\n",
      "105/105 [==============================] - loss: 0.3230 - time: 0.0030 s\n",
      "Epoch 116/1000\n",
      "105/105 [==============================] - loss: 0.3220 - time: 0.0000 s\n",
      "Epoch 117/1000\n",
      "105/105 [==============================] - loss: 0.3211 - time: 0.0000 s\n",
      "Epoch 118/1000\n",
      "105/105 [==============================] - loss: 0.3202 - time: 0.0000 s\n",
      "Epoch 119/1000\n",
      "105/105 [==============================] - loss: 0.3193 - time: 0.0127 s\n",
      "Epoch 120/1000\n",
      "105/105 [==============================] - loss: 0.3184 - time: 0.0026 s\n",
      "Epoch 121/1000\n",
      "105/105 [==============================] - loss: 0.3175 - time: 0.0013 s\n",
      "Epoch 122/1000\n",
      "105/105 [==============================] - loss: 0.3167 - time: 0.0086 s\n",
      "Epoch 123/1000\n",
      "105/105 [==============================] - loss: 0.3159 - time: 0.0007 s\n",
      "Epoch 124/1000\n",
      "105/105 [==============================] - loss: 0.3151 - time: 0.0080 s\n",
      "Epoch 125/1000\n",
      "105/105 [==============================] - loss: 0.3143 - time: 0.0040 s\n",
      "Epoch 126/1000\n",
      "105/105 [==============================] - loss: 0.3135 - time: 0.0030 s\n",
      "Epoch 127/1000\n",
      "105/105 [==============================] - loss: 0.3127 - time: 0.0030 s\n",
      "Epoch 128/1000\n",
      "105/105 [==============================] - loss: 0.3120 - time: 0.0030 s\n",
      "Epoch 129/1000\n",
      "105/105 [==============================] - loss: 0.3113 - time: 0.0028 s\n",
      "Epoch 130/1000\n",
      "105/105 [==============================] - loss: 0.3106 - time: 0.0000 s\n",
      "Epoch 131/1000\n",
      "105/105 [==============================] - loss: 0.3099 - time: 0.0000 s\n",
      "Epoch 132/1000\n",
      "105/105 [==============================] - loss: 0.3092 - time: 0.0000 s\n",
      "Epoch 133/1000\n",
      "105/105 [==============================] - loss: 0.3085 - time: 0.0168 s\n",
      "Epoch 134/1000\n",
      "105/105 [==============================] - loss: 0.3079 - time: 0.0089 s\n",
      "Epoch 135/1000\n",
      "105/105 [==============================] - loss: 0.3072 - time: 0.0007 s\n",
      "Epoch 136/1000\n",
      "105/105 [==============================] - loss: 0.3066 - time: 0.0000 s\n",
      "Epoch 137/1000\n",
      "105/105 [==============================] - loss: 0.3060 - time: 0.0096 s\n",
      "Epoch 138/1000\n",
      "105/105 [==============================] - loss: 0.3054 - time: 0.0040 s\n",
      "Epoch 139/1000\n",
      "105/105 [==============================] - loss: 0.3048 - time: 0.0019 s\n",
      "Epoch 140/1000\n",
      "105/105 [==============================] - loss: 0.3042 - time: 0.0092 s\n",
      "Epoch 141/1000\n",
      "105/105 [==============================] - loss: 0.3036 - time: 0.0041 s\n",
      "Epoch 142/1000\n",
      "105/105 [==============================] - loss: 0.3031 - time: 0.0050 s\n",
      "Epoch 143/1000\n",
      "105/105 [==============================] - loss: 0.3025 - time: 0.0030 s\n",
      "Epoch 144/1000\n",
      "105/105 [==============================] - loss: 0.3020 - time: 0.0046 s\n",
      "Epoch 145/1000\n",
      "105/105 [==============================] - loss: 0.3015 - time: 0.0046 s\n",
      "Epoch 146/1000\n",
      "105/105 [==============================] - loss: 0.3009 - time: 0.0040 s\n",
      "Epoch 147/1000\n",
      "105/105 [==============================] - loss: 0.3004 - time: 0.0030 s\n",
      "Epoch 148/1000\n",
      "105/105 [==============================] - loss: 0.2999 - time: 0.0030 s\n",
      "[Stop] Error threshold is reached.\n",
      "[Stop] Maximum number of iteration reached.\n"
     ]
    }
   ],
   "source": [
    "# Fit model, menjalankan 1000 epochs\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=4, learning_rate=0.1, error_threshold=0.3, random_state=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model: \"sequential\"\n",
      "-----------------------------------------------\n",
      " Layer (type)        Output Shape       Param #\n",
      "===============================================\n",
      " dense (Dense)       (None, 4)          20     \n",
      " dense (Dense)       (None, 6)          30     \n",
      " dense (Dense)       (None, 3)          15     \n",
      "===============================================\n",
      "Total params: 65\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Melakukan prediksi dan melihat hasil prediksi\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X_val)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_val, y_pred))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Melakukan prediksi dan melihat hasil prediksi\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Menyimpan model yang telah dibuat dalam json\n",
    "model.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
